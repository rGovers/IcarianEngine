#version 450

layout(location = 0) in vec2 vUV;

#!texture(0, colorSampler)
#!texture(1, normalSampler)
#!texture(2, specSampler)
#!texture(3, emissionSampler)
#!texture(4, depthSampler)
#!cubeshadowtexture(5, shadowSampler)

#!structure(CameraBuffer, 6, camBuffer)
#!structure(PointLightBuffer, 7, pointLightBuffer)

layout(location = 0) out vec4 fragColor;

const float NearPlane = 0.1;

void main()
{
    vec4 normal = texture(normalSampler, vUV);
    if (normal.w < 0.5)
    {
        discard;
    }

    float d = texture(depthSampler, vUV).x;

    vec4 cP = vec4(vUV * 2.0 + -1.0, d, 1.0);
    vec4 vP = camBuffer.InvProj * cP;
    vP /= vP.w;
    vec4 mP = camBuffer.InvView * vP;

    float lR = pointLightBuffer.Radius;
    vec4 lP = pointLightBuffer.LightPos;

    vec3 pTL = mP.xyz - lP.xyz;
    float dL = length(pTL);
    if (dL > lR)
    {
        discard;
    }

    vec3 lDir = -pTL / dL;

    // Not the correct was of doing it but do not have length component only depth
    // By doing so need to correct for cube projection
    // Again not the correct way of doing it but seems to kinda work outside of janky situations
    vec3 cFM = abs(lDir);
    float mF = max(max(cFM.x, cFM.y), cFM.z);

    float sD = texture(shadowSampler, pTL).x;
    float cD = NearPlane * lR / (lR - sD * (lR - NearPlane));
    // Need high bias to prevent shadow acne and additional prevention of janky projection correction
    if (cD < dL * mF - 0.01)
    {
        discard;
    }

    vec4 color = texture(colorSampler, vUV);
    vec4 spec = texture(specSampler, vUV);
    vec4 lCr = pointLightBuffer.LightColor;

    vec3 cF = camBuffer.View[2].xyz;

    float l = max(dot(lDir, normal.xyz), 0.0);

    vec3 hD = normalize(lDir + cF);
    float sA = dot(hD, normal.xyz);
    float s = max(pow(sA, spec.w), 0.0);

    float iV = max((lR - dL) / lR, 0.0);

    vec3 lC = color.xyz * l * lCr.xyz * lP.w * iV;
    vec3 sC = spec.xyz * s * lCr.xyz * lP.w * iV;
    
    fragColor = vec4(lC + sC, 1.0);
}